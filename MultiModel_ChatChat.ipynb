{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjM4JCz6eg7O"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install anthropic\n",
        "\n",
        "import openai\n",
        "import anthropic\n",
        "from getpass import getpass\n",
        "\n",
        "class AnsiColors:\n",
        "    USER = '\\033[96m'\n",
        "    ASSISTANT = '\\033[92m'\n",
        "    ERROR = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "\n",
        "# Constants\n",
        "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
        "ANTHROPIC_MODEL = \"claude-v1\"\n",
        "PROMPTS = [\"How would you assess the following proposal and what overall edits would you suggest, and how could the proposal be improved to more successfully meet the stated goal?\", \"In view of the following assessment and suggested improvements for your proposal, how, if at all, would you amend the proposal to give it the best opportunity to achieve the goal? Please include bullet points for each change you would include and bullet points for each update you would reject, including the reasons for each\", \"Please use the following feedback to redraft the proposal, and add a table in markdown at the end of the proposal enumerating each key way the proposal is designed to achieve the goal.\"]\n",
        "TEMPERATURE = 0.8\n",
        "MAX_TOKENS = 500\n",
        "\n",
        "# Get API keys\n",
        "openai_api_key = getpass('Enter your OpenAI API key: ')\n",
        "anthropic_api_key = getpass('Enter your Anthropic API key: ')\n",
        "\n",
        "# Initialize\n",
        "openai.api_key = openai_api_key\n",
        "anthropic_client = anthropic.Client(anthropic_api_key)\n",
        "messages = []\n",
        "\n",
        "# Get user input\n",
        "user_input = input(AnsiColors.USER + \"Enter your prompt: \" + AnsiColors.ENDC)\n",
        "\n",
        "# 1) Send user prompt to ChatGPT through OpenAI API\n",
        "messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=OPENAI_MODEL,\n",
        "    messages=messages,\n",
        "    temperature=TEMPERATURE\n",
        ")\n",
        "\n",
        "response_text = response['choices'][0]['message']['content']\n",
        "print(AnsiColors.ASSISTANT + \"OpenAI ChatGPT: \" + response_text + AnsiColors.ENDC)\n",
        "\n",
        "markdown_transcript = f\"## Transcript\\n\\n## Initial User Prompt\\n{user_input}\\n\\n## ChatGPT Response\\n{response_text}\\n\\n\"\n",
        "\n",
        "for idx, prompt in enumerate(PROMPTS):\n",
        "    if idx % 2 == 0:\n",
        "        # Even indices: ChatGPT\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt + \" \" + response_text})\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=OPENAI_MODEL,\n",
        "            messages=messages,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "        response_text = response['choices'][0]['message']['content']\n",
        "        print(AnsiColors.ASSISTANT + \"OpenAI ChatGPT: \" + response_text + AnsiColors.ENDC)\n",
        "        markdown_transcript += f\"## ChatGPT Prompt\\n{prompt}\\n\\n## ChatGPT Response\\n{response_text}\\n\\n\"\n",
        "    else:\n",
        "        # Odd indices: Claude\n",
        "        anthropic_prompt = \"\\n\\nHuman:\" + prompt + \" \" + response_text + \"\\n\\nAssistant:\"\n",
        "        anthropic_response = anthropic_client.completion(\n",
        "            prompt=anthropic_prompt,\n",
        "            model=ANTHROPIC_MODEL,\n",
        "            temperature=TEMPERATURE,\n",
        "            max_tokens_to_sample=MAX_TOKENS\n",
        "        )\n",
        "        response_text = anthropic_response[\"completion\"]\n",
        "        print(AnsiColors.ASSISTANT + \"Anthropic Claude: \" + response_text + AnsiColors.ENDC)\n",
        "        markdown_transcript += f\"## Claude Prompt\\n{prompt}\\n\\n## Claude Response\\n{response_text}\\n\\n\"\n",
        "\n",
        "markdown_transcript += \"\\n\\n---\\n\\n\"\n",
        "\n",
        "print(\"\\n\\n\" + AnsiColors.ASSISTANT + \"Transcript in Markdown Format:\" + AnsiColors.ENDC)\n",
        "print(markdown_transcript)"
      ]
    }
  ]
}